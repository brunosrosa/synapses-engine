#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Demonstra√ß√£o Pr√°tica do Sistema RAG Integrado
Para o projeto Recoloca.ai

Este script demonstra como usar o sistema RAG completo
com PyTorch GPU, otimiza√ß√µes e cache persistente.

Autor: @AgenteM_DevFastAPI
Vers√£o: 1.0
Data: Janeiro 2025
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import List, Dict, Any

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Adicionar path do projeto
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ...core_logic.rag_retriever import RAGRetriever
from ...core_logic.pytorch_gpu_retriever import PyTorchGPURetriever
from ...core_logic.pytorch_optimizations import OptimizedPyTorchRetriever

class RAGSystemDemo:
    """Demonstra√ß√£o do sistema RAG completo."""
    
    def __init__(self):
        self.retrievers = {}
        self.demo_documents = [
            "Python √© uma linguagem de programa√ß√£o de alto n√≠vel.",
            "FastAPI √© um framework web moderno para Python.",
            "PyTorch √© uma biblioteca de machine learning.",
            "CUDA permite computa√ß√£o paralela em GPUs NVIDIA.",
            "RAG combina recupera√ß√£o de informa√ß√µes com gera√ß√£o de texto.",
            "Supabase √© uma alternativa open source ao Firebase.",
            "Recoloca.ai √© uma plataforma de recoloca√ß√£o profissional.",
            "Machine Learning ajuda na an√°lise de curr√≠culos.",
            "APIs REST facilitam a integra√ß√£o entre sistemas.",
            "Cache melhora a performance de aplica√ß√µes web."
        ]
    
    def demo_backend_detection(self):
        """Demonstra detec√ß√£o autom√°tica de backend."""
        logger.info("üîç === DEMONSTRA√á√ÉO: DETEC√á√ÉO DE BACKEND ===")
        
        retriever = RAGRetriever()
        backend_info = retriever.get_backend_info()
        
        logger.info("üìä Informa√ß√µes do Backend:")
        for key, value in backend_info.items():
            logger.info(f"   {key}: {value}")
        
        return backend_info
    
    def demo_pytorch_gpu_retriever(self):
        """Demonstra uso do PyTorchGPURetriever."""
        logger.info("\nüöÄ === DEMONSTRA√á√ÉO: PYTORCH GPU RETRIEVER ===")
        
        # Criar retriever
        retriever = PyTorchGPURetriever(batch_size=32)
        self.retrievers['pytorch'] = retriever
        
        # Inicializar
        logger.info("üîß Inicializando retriever...")
        init_success = retriever.initialize()
        logger.info(f"   Inicializa√ß√£o: {'‚úÖ Sucesso' if init_success else '‚ùå Falhou'}")
        
        # Mostrar informa√ß√µes
        index_info = retriever.get_index_info()
        logger.info("üìã Informa√ß√µes do √çndice:")
        for key, value in index_info.items():
            logger.info(f"   {key}: {value}")
        
        # Mostrar estat√≠sticas
        stats = retriever.get_stats()
        logger.info("üìä Estat√≠sticas:")
        logger.info(f"   GPU: {stats.get('gpu_name', 'N/A')}")
        logger.info(f"   Mem√≥ria GPU Alocada: {stats.get('gpu_memory_allocated', 0) / 1024**3:.2f} GB")
        logger.info(f"   Dispositivo: {stats.get('device', 'N/A')}")
        
        return retriever
    
    def demo_optimized_retriever(self):
        """Demonstra uso do OptimizedPyTorchRetriever."""
        logger.info("\n‚ö° === DEMONSTRA√á√ÉO: OPTIMIZED PYTORCH RETRIEVER ===")
        
        # Criar retriever otimizado
        retriever = OptimizedPyTorchRetriever(
            cache_enabled=True,
            cache_ttl=300,  # 5 minutos
            batch_size=32,
            max_workers=4
        )
        self.retrievers['optimized'] = retriever
        
        # Inicializar
        logger.info("üîß Inicializando retriever otimizado...")
        init_success = retriever.initialize()
        logger.info(f"   Inicializa√ß√£o: {'‚úÖ Sucesso' if init_success else '‚ùå Falhou'}")
        
        # Mostrar informa√ß√µes do cache
        cache_info = retriever.get_cache_info()
        logger.info("üíæ Informa√ß√µes do Cache:")
        for key, value in cache_info.items():
            logger.info(f"   {key}: {value}")
        
        # Mostrar estat√≠sticas completas
        stats = retriever.get_stats()
        logger.info("üìä Estat√≠sticas Completas:")
        logger.info(f"   Cache Habilitado: {stats.get('cache_enabled', False)}")
        logger.info(f"   Batch Size: {stats.get('batch_size', 'N/A')}")
        logger.info(f"   Max Workers: {stats.get('max_workers', 'N/A')}")
        
        return retriever
    
    def demo_rag_retriever_configurations(self):
        """Demonstra diferentes configura√ß√µes do RAGRetriever."""
        logger.info("\nüîó === DEMONSTRA√á√ÉO: CONFIGURA√á√ïES RAG RETRIEVER ===")
        
        configurations = [
            {
                "name": "Auto (Padr√£o)",
                "params": {},
                "description": "Detec√ß√£o autom√°tica do melhor backend"
            },
            {
                "name": "PyTorch For√ßado",
                "params": {"force_pytorch": True},
                "description": "For√ßa uso do PyTorch GPU"
            },
            {
                "name": "Otimizado com Cache",
                "params": {
                    "force_pytorch": True,
                    "use_optimizations": True,
                    "cache_enabled": True,
                    "batch_size": 64
                },
                "description": "PyTorch otimizado com cache persistente"
            }
        ]
        
        for config in configurations:
            logger.info(f"\nüìù Testando: {config['name']}")
            logger.info(f"   Descri√ß√£o: {config['description']}")
            
            try:
                retriever = RAGRetriever(**config['params'])
                backend_info = retriever.get_backend_info()
                index_info = retriever.get_index_info()
                
                logger.info(f"   ‚úÖ Backend: {backend_info.get('current_backend', 'N/A')}")
                logger.info(f"   üìä Status: {index_info.get('status', 'N/A')}")
                
                self.retrievers[config['name']] = retriever
                
            except Exception as e:
                logger.error(f"   ‚ùå Erro: {e}")
    
    def demo_performance_comparison(self):
        """Demonstra compara√ß√£o de performance entre backends."""
        logger.info("\nüèÅ === DEMONSTRA√á√ÉO: COMPARA√á√ÉO DE PERFORMANCE ===")
        
        import torch
        
        if not torch.cuda.is_available():
            logger.warning("‚ö†Ô∏è GPU n√£o dispon√≠vel. Pulando teste de performance.")
            return
        
        # Teste de opera√ß√µes b√°sicas
        logger.info("üß™ Testando opera√ß√µes b√°sicas...")
        
        # Teste 1: Multiplica√ß√£o de matrizes
        sizes = [100, 500, 1000]
        
        for size in sizes:
            logger.info(f"\nüìè Testando matrizes {size}x{size}:")
            
            # CPU
            start_time = time.time()
            x_cpu = torch.randn(size, size)
            y_cpu = torch.randn(size, size)
            z_cpu = torch.mm(x_cpu, y_cpu)
            cpu_time = time.time() - start_time
            
            # GPU
            start_time = time.time()
            x_gpu = torch.randn(size, size, device='cuda')
            y_gpu = torch.randn(size, size, device='cuda')
            z_gpu = torch.mm(x_gpu, y_gpu)
            torch.cuda.synchronize()
            gpu_time = time.time() - start_time
            
            speedup = cpu_time / gpu_time if gpu_time > 0 else 0
            
            logger.info(f"   CPU: {cpu_time:.4f}s")
            logger.info(f"   GPU: {gpu_time:.4f}s")
            logger.info(f"   Speedup: {speedup:.2f}x")
    
    def demo_memory_usage(self):
        """Demonstra monitoramento de uso de mem√≥ria."""
        logger.info("\nüíæ === DEMONSTRA√á√ÉO: MONITORAMENTO DE MEM√ìRIA ===")
        
        import torch
        
        if torch.cuda.is_available():
            # Mem√≥ria GPU
            gpu_memory_allocated = torch.cuda.memory_allocated(0)
            gpu_memory_reserved = torch.cuda.memory_reserved(0)
            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory
            
            logger.info("üñ•Ô∏è Mem√≥ria GPU:")
            logger.info(f"   Alocada: {gpu_memory_allocated / 1024**3:.2f} GB")
            logger.info(f"   Reservada: {gpu_memory_reserved / 1024**3:.2f} GB")
            logger.info(f"   Total: {gpu_memory_total / 1024**3:.2f} GB")
            logger.info(f"   Uso: {(gpu_memory_allocated / gpu_memory_total) * 100:.1f}%")
        
        # Mem√≥ria do sistema
        try:
            import psutil
            memory = psutil.virtual_memory()
            
            logger.info("\nüñ•Ô∏è Mem√≥ria Sistema:")
            logger.info(f"   Total: {memory.total / 1024**3:.2f} GB")
            logger.info(f"   Dispon√≠vel: {memory.available / 1024**3:.2f} GB")
            logger.info(f"   Uso: {memory.percent:.1f}%")
            
        except ImportError:
            logger.info("\n‚ö†Ô∏è psutil n√£o dispon√≠vel para monitoramento de mem√≥ria do sistema")
    
    def demo_best_practices(self):
        """Demonstra melhores pr√°ticas de uso."""
        logger.info("\nüí° === DEMONSTRA√á√ÉO: MELHORES PR√ÅTICAS ===")
        
        practices = [
            {
                "title": "1. Detec√ß√£o Autom√°tica de Backend",
                "code": "retriever = RAGRetriever()  # Auto-detecta melhor backend",
                "benefit": "Adapta automaticamente ao hardware dispon√≠vel"
            },
            {
                "title": "2. For√ßar PyTorch para GPU",
                "code": "retriever = RAGRetriever(force_pytorch=True)",
                "benefit": "Garante uso de GPU quando dispon√≠vel"
            },
            {
                "title": "3. Usar Otimiza√ß√µes com Cache",
                "code": "retriever = RAGRetriever(use_optimizations=True, cache_enabled=True)",
                "benefit": "M√°xima performance com cache persistente"
            },
            {
                "title": "4. Configurar Batch Size",
                "code": "retriever = RAGRetriever(batch_size=64)",
                "benefit": "Otimiza throughput para m√∫ltiplas consultas"
            },
            {
                "title": "5. Monitorar Performance",
                "code": "stats = retriever.get_stats(); cache_info = retriever.get_cache_info()",
                "benefit": "Permite otimiza√ß√£o baseada em m√©tricas reais"
            }
        ]
        
        for practice in practices:
            logger.info(f"\nüìã {practice['title']}")
            logger.info(f"   C√≥digo: {practice['code']}")
            logger.info(f"   Benef√≠cio: {practice['benefit']}")
    
    def run_complete_demo(self):
        """Executa demonstra√ß√£o completa do sistema."""
        logger.info("üéØ INICIANDO DEMONSTRA√á√ÉO COMPLETA DO SISTEMA RAG")
        logger.info("=" * 70)
        
        try:
            # 1. Detec√ß√£o de backend
            self.demo_backend_detection()
            
            # 2. PyTorch GPU Retriever
            self.demo_pytorch_gpu_retriever()
            
            # 3. Optimized Retriever
            self.demo_optimized_retriever()
            
            # 4. Configura√ß√µes RAG Retriever
            self.demo_rag_retriever_configurations()
            
            # 5. Compara√ß√£o de performance
            self.demo_performance_comparison()
            
            # 6. Monitoramento de mem√≥ria
            self.demo_memory_usage()
            
            # 7. Melhores pr√°ticas
            self.demo_best_practices()
            
            logger.info("\n" + "=" * 70)
            logger.info("üéâ DEMONSTRA√á√ÉO CONCLU√çDA COM SUCESSO!")
            logger.info("\nüí° RESUMO DAS FUNCIONALIDADES DEMONSTRADAS:")
            logger.info("   ‚úÖ Detec√ß√£o autom√°tica de backend")
            logger.info("   ‚úÖ PyTorch GPU Retriever")
            logger.info("   ‚úÖ Optimized Retriever com cache")
            logger.info("   ‚úÖ M√∫ltiplas configura√ß√µes RAG")
            logger.info("   ‚úÖ Compara√ß√£o de performance")
            logger.info("   ‚úÖ Monitoramento de mem√≥ria")
            logger.info("   ‚úÖ Melhores pr√°ticas de uso")
            
            logger.info("\nüöÄ O sistema RAG est√° pronto para produ√ß√£o!")
            
        except Exception as e:
            logger.error(f"‚ùå Erro durante a demonstra√ß√£o: {e}")
            raise

def main():
    """Fun√ß√£o principal."""
    demo = RAGSystemDemo()
    demo.run_complete_demo()

if __name__ == "__main__":
    main()