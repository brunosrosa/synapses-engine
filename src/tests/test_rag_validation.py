#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de Valida√ß√£o Completa do Sistema RAG - Recoloca.ai

Este script executa uma valida√ß√£o completa do sistema RAG incluindo:
- Teste de conectividade e performance
- Valida√ß√£o contextual espec√≠fica para @AgenteM_DevFastAPI
- Teste de qualidade das respostas
- Verifica√ß√£o da infraestrutura

Autor: @AgenteM_DevFastAPI
Vers√£o: 1.0
Data: Junho 2025
"""

import asyncio
import json
import logging
import sys
import time
from pathlib import Path
from typing import Dict, List, Any

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Adicionar core_logic ao path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from rag_infra.src.core.rag_retriever import RAGRetriever
    from rag_infra.src.core.core_logic.rag_indexer import RAGIndexer
    from rag_infra.src.core.embedding_model import EmbeddingModelManager as EmbeddingModel
except ImportError as e:
    logger.error(f"Erro ao importar m√≥dulos RAG: {e}")
    print(f"Erro detalhado: {e}")
    # N√£o usar sys.exit(1) em testes pytest
    raise ImportError(f"Falha ao importar m√≥dulos RAG: {e}")

class RAGValidator:
    """Classe para valida√ß√£o completa do sistema RAG"""
    
    def __init__(self):
        self.retriever = None
        self.indexer = None
        self.test_results = {
            "timestamp": time.time(),
            "tests": {},
            "overall_status": "pending",
            "recommendations": []
        }
    
    async def initialize_system(self) -> bool:
        """Inicializa o sistema RAG"""
        try:
            logger.info("[EMOJI] Inicializando sistema RAG...")
            
            # Inicializar indexer
            self.indexer = RAGIndexer()
            
            # Inicializar retriever
            success = initialize_retriever(force_pytorch=True)
            if not success:
                raise Exception("Falha ao inicializar retriever")
            
            # Obter inst√¢ncia do retriever
            self.retriever = get_retriever(force_pytorch=True)
            
            if self.retriever is None:
                raise Exception("Falha ao obter inst√¢ncia do retriever")
            
            logger.info("[OK] Sistema RAG inicializado com sucesso")
            return True
            
        except Exception as e:
            logger.error(f"[ERROR] Erro na inicializa√ß√£o: {e}")
            self.test_results["tests"]["initialization"] = {
                "status": "failed",
                "error": str(e)
            }
            return False
    
    async def test_connectivity_performance(self) -> Dict[str, Any]:
        """Testa conectividade e performance do sistema"""
        logger.info("[EMOJI] Testando conectividade e performance...")
        
        test_result = {
            "status": "pending",
            "response_times": [],
            "queries_tested": 0,
            "average_response_time": 0,
            "errors": []
        }
        
        # Queries de teste para performance
        test_queries = [
            "FastAPI backend development",
            "Supabase integration",
            "MVP requirements",
            "authentication system",
            "API endpoints"
        ]
        
        try:
            for query in test_queries:
                start_time = time.time()
                
                try:
                    results = self.retriever.search(query, top_k=3)
                    response_time = time.time() - start_time
                    
                    test_result["response_times"].append(response_time)
                    test_result["queries_tested"] += 1
                    
                    logger.info(f"Query '{query}': {response_time:.3f}s - {len(results)} resultados")
                    
                except Exception as e:
                    test_result["errors"].append(f"Query '{query}': {str(e)}")
                    logger.error(f"Erro na query '{query}': {e}")
            
            # Calcular m√©tricas
            if test_result["response_times"]:
                test_result["average_response_time"] = sum(test_result["response_times"]) / len(test_result["response_times"])
                test_result["status"] = "success" if len(test_result["errors"]) == 0 else "partial"
            else:
                test_result["status"] = "failed"
            
            logger.info(f"[OK] Teste de performance conclu√≠do: {test_result['average_response_time']:.3f}s m√©dio")
            
        except Exception as e:
            test_result["status"] = "failed"
            test_result["errors"].append(str(e))
            logger.error(f"[ERROR] Erro no teste de performance: {e}")
        
        return test_result
    
    async def test_context_validation(self) -> Dict[str, Any]:
        """Valida contexto espec√≠fico para @AgenteM_DevFastAPI"""
        logger.info("[EMOJI] Testando valida√ß√£o contextual para @AgenteM_DevFastAPI...")
        
        test_result = {
            "status": "pending",
            "context_queries": [],
            "quality_score": 0,
            "relevant_documents_found": 0
        }
        
        # Queries espec√≠ficas para desenvolvimento FastAPI
        context_queries = [
            "FastAPI backend architecture Recoloca.ai",
            "Supabase authentication integration",
            "API endpoints specification",
            "Python development patterns",
            "MVP backend requirements"
        ]
        
        try:
            total_relevance = 0
            total_documents = 0
            
            for query in context_queries:
                try:
                    results = self.retriever.search(query, top_k=5)
                    
                    query_result = {
                        "query": query,
                        "results_count": len(results),
                        "top_documents": []
                    }
                    
                    for result in results[:3]:  # Top 3 resultados
                        # Converter SearchResult para dict se necess√°rio
                        if hasattr(result, 'to_dict'):
                            result_dict = result.to_dict()
                        else:
                            result_dict = result
                        
                        query_result["top_documents"].append({
                            "document": result_dict.get("document", "Unknown"),
                            "score": result_dict.get("score", 0),
                            "content_preview": result_dict.get("content", "")[:100] + "..."
                        })
                    
                    test_result["context_queries"].append(query_result)
                    total_documents += len(results)
                    
                    # Calcular relev√¢ncia baseada na presen√ßa de documentos
                    if len(results) > 0:
                        total_relevance += min(len(results), 5)  # Max 5 pontos por query
                    
                    logger.info(f"Query contextual '{query}': {len(results)} documentos encontrados")
                    
                except Exception as e:
                    logger.error(f"Erro na query contextual '{query}': {e}")
            
            # Calcular score de qualidade
            max_possible_score = len(context_queries) * 5
            test_result["quality_score"] = (total_relevance / max_possible_score) * 100 if max_possible_score > 0 else 0
            test_result["relevant_documents_found"] = total_documents
            
            if test_result["quality_score"] >= 70:
                test_result["status"] = "excellent"
            elif test_result["quality_score"] >= 50:
                test_result["status"] = "good"
            elif test_result["quality_score"] >= 30:
                test_result["status"] = "acceptable"
            else:
                test_result["status"] = "poor"
            
            logger.info(f"[OK] Valida√ß√£o contextual conclu√≠da: {test_result['quality_score']:.1f}% qualidade")
            
        except Exception as e:
            test_result["status"] = "failed"
            test_result["error"] = str(e)
            logger.error(f"[ERROR] Erro na valida√ß√£o contextual: {e}")
        
        return test_result
    
    async def test_mcp_integration(self) -> Dict[str, Any]:
        """Testa a integra√ß√£o MCP"""
        logger.info("[EMOJI] Testando integra√ß√£o MCP...")
        
        test_result = {
            "status": "pending",
            "mcp_server_available": False,
            "config_valid": False
        }
        
        try:
            # Verificar se o arquivo de configura√ß√£o MCP existe
            mcp_config_path = Path(__file__).parent.parent / "config" / "trae_mcp_config.json"
            
            if mcp_config_path.exists():
                with open(mcp_config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    test_result["config_valid"] = True
                    test_result["config_content"] = config
                    logger.info("[OK] Configura√ß√£o MCP encontrada e v√°lida")
            else:
                logger.warning("[WARNING] Arquivo de configura√ß√£o MCP n√£o encontrado")
            
            # Verificar se o servidor MCP existe
            mcp_server_path = Path(__file__).parent / "mcp_server.py"
            
            if mcp_server_path.exists():
                test_result["mcp_server_available"] = True
                logger.info("[OK] Servidor MCP dispon√≠vel")
            else:
                logger.warning("[WARNING] Servidor MCP n√£o encontrado")
            
            # Determinar status geral
            if test_result["config_valid"] and test_result["mcp_server_available"]:
                test_result["status"] = "ready"
            elif test_result["mcp_server_available"]:
                test_result["status"] = "partial"
            else:
                test_result["status"] = "not_ready"
            
        except Exception as e:
            test_result["status"] = "failed"
            test_result["error"] = str(e)
            logger.error(f"[ERROR] Erro no teste MCP: {e}")
        
        return test_result
    
    async def generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes baseadas nos testes"""
        recommendations = []
        
        # Analisar resultados dos testes
        connectivity = self.test_results["tests"].get("connectivity_performance", {})
        context = self.test_results["tests"].get("context_validation", {})
        mcp = self.test_results["tests"].get("mcp_integration", {})
        
        # Recomenda√ß√µes de performance
        if connectivity.get("average_response_time", 0) > 2.0:
            recommendations.append("[EMOJI] [PERFORMANCE] Tempo de resposta alto. Considere otimizar o √≠ndice ou usar cache.")
        elif connectivity.get("average_response_time", 0) < 0.5:
            recommendations.append("üü¢ [PERFORMANCE] Excelente tempo de resposta. Sistema otimizado.")
        
        # Recomenda√ß√µes de qualidade
        quality_score = context.get("quality_score", 0)
        if quality_score >= 70:
            recommendations.append("üü¢ [QUALITY] Excelente qualidade contextual. RAG pronto para produ√ß√£o.")
        elif quality_score >= 50:
            recommendations.append("üü° [QUALITY] Boa qualidade contextual. Considere adicionar mais documentos espec√≠ficos.")
        else:
            recommendations.append("[EMOJI] [QUALITY] Qualidade contextual baixa. Re-indexa√ß√£o ou revis√£o de documentos necess√°ria.")
        
        # Recomenda√ß√µes MCP
        mcp_status = mcp.get("status", "unknown")
        if mcp_status == "ready":
            recommendations.append("üü¢ [MCP] Sistema MCP pronto para integra√ß√£o com Trae IDE.")
        elif mcp_status == "partial":
            recommendations.append("üü° [MCP] Sistema MCP parcialmente configurado. Verificar configura√ß√£o.")
        else:
            recommendations.append("[EMOJI] [MCP] Sistema MCP n√£o configurado. Configura√ß√£o necess√°ria para Trae IDE.")
        
        return recommendations
    
    async def run_full_validation(self) -> Dict[str, Any]:
        """Executa valida√ß√£o completa do sistema RAG"""
        logger.info("[START] Iniciando valida√ß√£o completa do sistema RAG...")
        
        # Inicializar sistema
        if not await self.initialize_system():
            self.test_results["overall_status"] = "failed"
            return self.test_results
        
        # Executar testes
        try:
            # Teste de conectividade e performance
            self.test_results["tests"]["connectivity_performance"] = await self.test_connectivity_performance()
            
            # Teste de valida√ß√£o contextual
            self.test_results["tests"]["context_validation"] = await self.test_context_validation()
            
            # Teste de integra√ß√£o MCP
            self.test_results["tests"]["mcp_integration"] = await self.test_mcp_integration()
            
            # Gerar recomenda√ß√µes
            self.test_results["recommendations"] = await self.generate_recommendations()
            
            # Determinar status geral
            failed_tests = [test for test in self.test_results["tests"].values() if test.get("status") == "failed"]
            
            if len(failed_tests) == 0:
                self.test_results["overall_status"] = "success"
            elif len(failed_tests) < len(self.test_results["tests"]) / 2:
                self.test_results["overall_status"] = "partial"
            else:
                self.test_results["overall_status"] = "failed"
            
            logger.info(f"[OK] Valida√ß√£o completa conclu√≠da: {self.test_results['overall_status']}")
            
        except Exception as e:
            logger.error(f"[ERROR] Erro durante valida√ß√£o: {e}")
            self.test_results["overall_status"] = "failed"
            self.test_results["error"] = str(e)
        
        return self.test_results
    
    def save_results(self, filename: str = "utils/rag_validation_results.json"):
        """Salva os resultados da valida√ß√£o"""
        try:
            results_path = Path(__file__).parent / filename
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, indent=2, ensure_ascii=False)
            logger.info(f"[EMOJI] Resultados salvos em: {results_path}")
        except Exception as e:
            logger.error(f"[ERROR] Erro ao salvar resultados: {e}")
    
    def print_summary(self):
        """Imprime resumo dos resultados"""
        print("\n" + "="*60)
        print("[EMOJI] RESUMO DA VALIDA√á√ÉO RAG - RECOLOCA.AI")
        print("="*60)
        
        print(f"\n[EMOJI] STATUS GERAL: {self.test_results['overall_status'].upper()}")
        
        print("\n[EMOJI] RESULTADOS DOS TESTES:")
        for test_name, test_result in self.test_results["tests"].items():
            status_icon = {
                "success": "[OK]",
                "excellent": "[EMOJI]",
                "good": "[OK]",
                "acceptable": "üü°",
                "partial": "üü°",
                "poor": "[EMOJI]",
                "failed": "[ERROR]",
                "ready": "[OK]",
                "not_ready": "[ERROR]"
            }.get(test_result.get("status", "unknown"), "[EMOJI]")
            
            print(f"  {status_icon} {test_name.replace('_', ' ').title()}: {test_result.get('status', 'unknown')}")
        
        print("\n[EMOJI] RECOMENDA√á√ïES:")
        for rec in self.test_results.get("recommendations", []):
            print(f"  {rec}")
        
        print("\n" + "="*60)

async def main():
    """Fun√ß√£o principal"""
    validator = RAGValidator()
    
    # Executar valida√ß√£o completa
    results = await validator.run_full_validation()
    
    # Salvar resultados
    validator.save_results()
    
    # Imprimir resumo
    validator.print_summary()
    
    # Retornar c√≥digo de sa√≠da baseado no status
    if results["overall_status"] == "success":
        print("\n[EMOJI] Sistema RAG totalmente operacional!")
        return 0
    elif results["overall_status"] == "partial":
        print("\n[WARNING] Sistema RAG parcialmente operacional. Verificar recomenda√ß√µes.")
        return 1
    else:
        print("\n[ERROR] Sistema RAG com problemas cr√≠ticos. Corre√ß√µes necess√°rias.")
        return 2

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)