{
  "timestamp": 1750282063.6733804,
  "tests": {
    "backend_detection": {
      "status": "success",
      "backend_info": {
        "current_backend": "Auto",
        "recommended_backend": "pytorch",
        "gpu_available": true,
        "cuda_device_count": 1,
        "gpu_name": "NVIDIA GeForce RTX 2060",
        "gpu_memory_total": 6442123264
      },
      "gpu_available": true,
      "recommended_backend": "pytorch"
    },
    "pytorch_gpu_retriever": {
      "status": "success",
      "initialization": true,
      "index_info": {
        "status": "not_loaded",
        "backend": "PyTorch",
        "device": "cuda",
        "documents_count": 0,
        "embeddings_shape": null
      },
      "stats": {
        "is_loaded": false,
        "device": "cuda",
        "cuda_available": true,
        "documents_count": 0,
        "cache_size": 0,
        "batch_size": 1000,
        "gpu_name": "NVIDIA GeForce RTX 2060",
        "gpu_memory_allocated": 2279670784,
        "gpu_memory_reserved": 2294284288
      },
      "device": "cuda"
    },
    "optimized_retriever": {
      "status": "success",
      "initialization": true,
      "cache_info": {
        "enabled": true,
        "size": 0,
        "hits": 0,
        "misses": 0,
        "hit_rate": 0,
        "ttl": 300,
        "max_size": 1000,
        "memory_usage_mb": 0.0
      },
      "stats": {
        "total_queries": 0,
        "cache_hits": 0,
        "cache_misses": 0,
        "batch_queries": 0,
        "single_queries": 0,
        "total_time": 0.0,
        "avg_query_time": 0.0,
        "cache": {
          "entries": 0,
          "max_entries": 1000,
          "hit_rate": 0,
          "total_hits": 0,
          "total_misses": 0,
          "evictions": 0,
          "saves": 0,
          "loads": 0,
          "cache_size_mb": 0.0
        },
        "index_info": {
          "status": "not_loaded",
          "backend": "PyTorch",
          "device": "cuda",
          "documents_count": 0,
          "embeddings_shape": null
        }
      },
      "optimizations_enabled": true
    },
    "rag_retriever_integration": {
      "status": "success",
      "configurations": {
        "auto": {
          "status": "success",
          "backend_info": {
            "current_backend": "Auto",
            "recommended_backend": "pytorch",
            "gpu_available": true,
            "cuda_device_count": 1,
            "gpu_name": "NVIDIA GeForce RTX 2060",
            "gpu_memory_total": 6442123264
          },
          "index_info": {
            "loaded": false,
            "error": "Índice não carregado"
          }
        },
        "pytorch": {
          "status": "success",
          "backend_info": {
            "current_backend": "PyTorch",
            "recommended_backend": "pytorch",
            "gpu_available": true,
            "cuda_device_count": 1,
            "gpu_name": "NVIDIA GeForce RTX 2060",
            "gpu_memory_total": 6442123264
          },
          "index_info": {
            "loaded": false,
            "error": "Índice não carregado"
          }
        },
        "optimized": {
          "status": "success",
          "backend_info": {
            "current_backend": "OptimizedPyTorch",
            "recommended_backend": "pytorch",
            "gpu_available": true,
            "cuda_device_count": 1,
            "gpu_name": "NVIDIA GeForce RTX 2060",
            "gpu_memory_total": 6442123264
          },
          "index_info": {
            "loaded": false,
            "error": "Índice não carregado"
          }
        }
      }
    },
    "performance_baseline": {
      "status": "success",
      "gpu_available": true,
      "matrix_multiplication_time": 0.00988626480102539,
      "cosine_similarity_time": 0.0017476081848144531,
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 2060"
    }
  },
  "summary": {
    "total_tests": 5,
    "passed_tests": 5,
    "success_rate": 100.0,
    "status": "excellent"
  },
  "recommendations": [
    {
      "priority": "high",
      "category": "hardware",
      "message": "GPU detectada e funcionando. Use PyTorch GPU para melhor performance."
    },
    {
      "priority": "high",
      "category": "configuration",
      "message": "Use force_pytorch=True para melhor performance com GPU."
    },
    {
      "priority": "medium",
      "category": "optimization",
      "message": "OptimizedPyTorchRetriever disponível. Use para cache persistente e batch processing."
    },
    {
      "priority": "low",
      "category": "performance",
      "message": "Performance GPU excelente. Sistema otimizado para produção."
    }
  ]
}